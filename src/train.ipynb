{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-11T12:05:42.754051Z",
     "start_time": "2025-03-11T12:05:24.510716Z"
    }
   },
   "source": [
    "import evaluate\n",
    "import numpy\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import VisionEncoderDecoderModel, GPT2TokenizerFast, ViTImageProcessor, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "# load the rouge and bleu metrics\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bd3ba304f437408892802e3c497d91d4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ImportError",
     "evalue": "To be able to use evaluate-metric/rouge, you need to install the following dependencies['rouge_score', 'nltk'] using 'pip install rouge_score # Here to have a nice missing dependency error message early on' for instance'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 9\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m VisionEncoderDecoderModel, GPT2TokenizerFast, ViTImageProcessor\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# load the rouge and bleu metrics\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m rouge \u001B[38;5;241m=\u001B[39m evaluate\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrouge\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     10\u001B[0m bleu \u001B[38;5;241m=\u001B[39m evaluate\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbleu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     12\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\dsa5204-project\\Lib\\site-packages\\evaluate\\loading.py:748\u001B[0m, in \u001B[0;36mload\u001B[1;34m(path, config_name, module_type, process_id, num_process, cache_dir, experiment_id, keep_in_memory, download_config, download_mode, revision, **init_kwargs)\u001B[0m\n\u001B[0;32m    703\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Load a [`~evaluate.EvaluationModule`].\u001B[39;00m\n\u001B[0;32m    704\u001B[0m \n\u001B[0;32m    705\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    745\u001B[0m \u001B[38;5;124;03m    ```\u001B[39;00m\n\u001B[0;32m    746\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    747\u001B[0m download_mode \u001B[38;5;241m=\u001B[39m DownloadMode(download_mode \u001B[38;5;129;01mor\u001B[39;00m DownloadMode\u001B[38;5;241m.\u001B[39mREUSE_DATASET_IF_EXISTS)\n\u001B[1;32m--> 748\u001B[0m evaluation_module \u001B[38;5;241m=\u001B[39m evaluation_module_factory(\n\u001B[0;32m    749\u001B[0m     path, module_type\u001B[38;5;241m=\u001B[39mmodule_type, revision\u001B[38;5;241m=\u001B[39mrevision, download_config\u001B[38;5;241m=\u001B[39mdownload_config, download_mode\u001B[38;5;241m=\u001B[39mdownload_mode\n\u001B[0;32m    750\u001B[0m )\n\u001B[0;32m    751\u001B[0m evaluation_cls \u001B[38;5;241m=\u001B[39m import_main_class(evaluation_module\u001B[38;5;241m.\u001B[39mmodule_path)\n\u001B[0;32m    752\u001B[0m evaluation_instance \u001B[38;5;241m=\u001B[39m evaluation_cls(\n\u001B[0;32m    753\u001B[0m     config_name\u001B[38;5;241m=\u001B[39mconfig_name,\n\u001B[0;32m    754\u001B[0m     process_id\u001B[38;5;241m=\u001B[39mprocess_id,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    760\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minit_kwargs,\n\u001B[0;32m    761\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\dsa5204-project\\Lib\\site-packages\\evaluate\\loading.py:680\u001B[0m, in \u001B[0;36mevaluation_module_factory\u001B[1;34m(path, module_type, revision, download_config, download_mode, force_local_path, dynamic_modules_path, **download_kwargs)\u001B[0m\n\u001B[0;32m    678\u001B[0m                 \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m    679\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e1, (\u001B[38;5;167;01mConnectionError\u001B[39;00m, \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m)):\n\u001B[1;32m--> 680\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m e1 \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    681\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\n\u001B[0;32m    682\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCouldn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt find a module script at \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrelative_to_absolute_path(combined_path)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    683\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModule \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m doesn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt exist on the Hugging Face Hub either.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    684\u001B[0m         ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    685\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\dsa5204-project\\Lib\\site-packages\\evaluate\\loading.py:639\u001B[0m, in \u001B[0;36mevaluation_module_factory\u001B[1;34m(path, module_type, revision, download_config, download_mode, force_local_path, dynamic_modules_path, **download_kwargs)\u001B[0m\n\u001B[0;32m    631\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m current_type \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetric\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcomparison\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmeasurement\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m    632\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    633\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m HubEvaluationModuleFactory(\n\u001B[0;32m    634\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mevaluate-\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcurrent_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    635\u001B[0m             revision\u001B[38;5;241m=\u001B[39mrevision,\n\u001B[0;32m    636\u001B[0m             download_config\u001B[38;5;241m=\u001B[39mdownload_config,\n\u001B[0;32m    637\u001B[0m             download_mode\u001B[38;5;241m=\u001B[39mdownload_mode,\n\u001B[0;32m    638\u001B[0m             dynamic_modules_path\u001B[38;5;241m=\u001B[39mdynamic_modules_path,\n\u001B[1;32m--> 639\u001B[0m         )\u001B[38;5;241m.\u001B[39mget_module()\n\u001B[0;32m    640\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m:\n\u001B[0;32m    641\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\dsa5204-project\\Lib\\site-packages\\evaluate\\loading.py:489\u001B[0m, in \u001B[0;36mHubEvaluationModuleFactory.get_module\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    486\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m err\n\u001B[0;32m    488\u001B[0m imports \u001B[38;5;241m=\u001B[39m get_imports(local_path)\n\u001B[1;32m--> 489\u001B[0m local_imports \u001B[38;5;241m=\u001B[39m _download_additional_modules(\n\u001B[0;32m    490\u001B[0m     name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname,\n\u001B[0;32m    491\u001B[0m     base_path\u001B[38;5;241m=\u001B[39mhf_hub_url(path\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m, revision\u001B[38;5;241m=\u001B[39mrevision),\n\u001B[0;32m    492\u001B[0m     imports\u001B[38;5;241m=\u001B[39mimports,\n\u001B[0;32m    493\u001B[0m     download_config\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdownload_config,\n\u001B[0;32m    494\u001B[0m )\n\u001B[0;32m    495\u001B[0m \u001B[38;5;66;03m# copy the script and the files in an importable directory\u001B[39;00m\n\u001B[0;32m    496\u001B[0m dynamic_modules_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdynamic_modules_path \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdynamic_modules_path \u001B[38;5;28;01melse\u001B[39;00m init_dynamic_modules()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\dsa5204-project\\Lib\\site-packages\\evaluate\\loading.py:265\u001B[0m, in \u001B[0;36m_download_additional_modules\u001B[1;34m(name, base_path, imports, download_config)\u001B[0m\n\u001B[0;32m    263\u001B[0m         needs_to_be_installed\u001B[38;5;241m.\u001B[39madd((library_import_name, library_import_path))\n\u001B[0;32m    264\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m needs_to_be_installed:\n\u001B[1;32m--> 265\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[0;32m    266\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTo be able to use \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, you need to install the following dependencies\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    267\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m[lib_name\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mlib_name,\u001B[38;5;250m \u001B[39mlib_path\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39mneeds_to_be_installed]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m using \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpip install \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    268\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin([lib_path\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mlib_name,\u001B[38;5;250m \u001B[39mlib_path\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39mneeds_to_be_installed])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m for instance\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    269\u001B[0m     )\n\u001B[0;32m    270\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m local_imports\n",
      "\u001B[1;31mImportError\u001B[0m: To be able to use evaluate-metric/rouge, you need to install the following dependencies['rouge_score', 'nltk'] using 'pip install rouge_score # Here to have a nice missing dependency error message early on' for instance'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "encoder_model = \"microsoft/swin-base-patch4-window7-224-in22k\"\n",
    "decoder_model = \"gpt2\"\n",
    "model = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(encoder_model, decoder_model).to(device)"
   ],
   "id": "6c481d817ffd901d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tokenizer = GPT2TokenizerFast.from_pretrained(decoder_model)\n",
    "image_processor = ViTImageProcessor.from_pretrained(encoder_model)"
   ],
   "id": "6c5cb2d6b7b1681e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.eos_token_id = tokenizer.eos_token_id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.decoder_start_token_id = tokenizer.bos_token_id"
   ],
   "id": "9bd88660132428d7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Here is a definition of each special token defined above:\n",
    "\n",
    "- bos_token_id is the ID of the token that represents the beginning of the sentence.\n",
    "- eos_token_id is the ID of the token that represents the end of the sentence.\n",
    "- decoder_start_token_id is used to indicate the starting point of the decoder to start generating the target sequence (in our case, the caption).\n",
    "- pad_token_id is used to pad short sequences of text into a fixed length.\n",
    "- cls_token_id represents the classification token and is typically used by BERT and other tokenizers as the first token in a sequence of text before the actual sentence starts.\n",
    "\n",
    "\n",
    "The GPT2 tokenizer does not have the pad_token_id and decoder_start_token_id but it has bos_token_id and eos_token_id. Therefore, we can simply set the pad_token as the eos_token and decoder_start_token_id as the bos_token_id.\n",
    "\n",
    "For other language models such as BERT, we set the docoder_start_token_id as the cls_token_id.\n",
    "\n",
    "The reason we're setting all of these is that when we assemble our model, these token ids are not loaded by default. If we do not set them now, we'll get weird errors later in training."
   ],
   "id": "3665c89aaf2b8c3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# max_length = 32\n",
    "# coco_dataset_ratio = 50\n",
    "# train_ds = load_dataset(\"HuggingFaceM4/COCO\", split=f\"train[:{coco_dataset_ratio}%]\")\n",
    "# valid_ds = load_dataset(\"HuggingFaceM4/COCO\", split=f\"validation[:{coco_dataset_ratio}%]\")\n",
    "# test_ds = load_dataset(\"HuggingFaceM4/COCO\", split=\"test\")"
   ],
   "id": "43ec34d4f1007e27"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# train_ds = train_ds.filter(lambda item: np.array(item[\"image\"]).ndim in [3, 4], num_proc=2)\n",
    "# valid_ds = valid_ds.filter(lambda item: np.array(item[\"image\"]).ndim in [3, 4], num_proc=2)\n",
    "# test_ds = test_ds.filter(lambda item: np.array(item[\"image\"]).ndim in [3, 4], num_proc=2)"
   ],
   "id": "8bdad00d5833d70e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# def preprocess(items):\n",
    "#   # preprocess the image\n",
    "#   pixel_values = image_processor(items[\"image\"], return_tensors=\"pt\").pixel_values.to(device)\n",
    "#   # tokenize the caption with truncation and padding\n",
    "#   targets = tokenizer([ sentence[\"raw\"] for sentence in items[\"sentences\"] ], \n",
    "#                       max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\").to(device)\n",
    "#   return {'pixel_values': pixel_values, 'labels': targets[\"input_ids\"]}\n",
    "# \n",
    "# # using with_transform to preprocess the dataset during training\n",
    "# train_dataset = train_ds.with_transform(preprocess)\n",
    "# valid_dataset = valid_ds.with_transform(preprocess)\n",
    "# test_dataset  = test_ds.with_transform(preprocess)"
   ],
   "id": "bee6b4f75f91f9ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
    "        'labels': torch.stack([x['labels'] for x in batch])\n",
    "    }"
   ],
   "id": "1fe29f4eedc52374"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def compute_metrics(eval_pred):\n",
    "  pred = eval_pred.label_ids\n",
    "  labels = eval_pred.predictions\n",
    "  # decode the predictions and labels\n",
    "  pred_str = tokenizer.batch_decode(pred, skip_special_tokens=True)\n",
    "  labels_str = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "  # compute the rouge score\n",
    "  rouge_result = rouge.compute(predictions=pred_str, references=labels_str)\n",
    "  # multiply by 100 to get the same scale as the rouge score\n",
    "  rouge_result = {k: round(v * 100, 4) for k, v in rouge_result.items()}\n",
    "  # compute the bleu score\n",
    "  bleu_result = bleu.compute(predictions=pred_str, references=labels_str)\n",
    "  # get the length of the generated captions\n",
    "  generation_length = bleu_result[\"translation_length\"]\n",
    "  return {\n",
    "        **rouge_result, \n",
    "        \"bleu\": round(bleu_result[\"bleu\"] * 100, 4), \n",
    "        \"gen_len\": bleu_result[\"translation_length\"] / len(pred)\n",
    "  }"
   ],
   "id": "9abe066b021bd89c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "num_epochs = 2 # number of epochs\n",
    "batch_size = 16 # the size of batches"
   ],
   "id": "47bbee926b99a16a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# define the training arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    predict_with_generate=True,             # use generate to calculate the loss\n",
    "    num_train_epochs=num_epochs,            # number of epochs\n",
    "    evaluation_strategy=\"steps\",            # evaluate after each eval_steps\n",
    "    eval_steps=2000,                        # evaluate after each 2000 steps\n",
    "    logging_steps=2000,                     # log after each 2000 steps\n",
    "    save_steps=2000,                        # save after each 2000 steps\n",
    "    per_device_train_batch_size=batch_size, # batch size for training\n",
    "    per_device_eval_batch_size=batch_size,  # batch size for evaluation\n",
    "    output_dir=\"vit-swin-base-224-gpt2-image-captioning\", # output directory\n",
    "    # push_to_hub=True # whether you want to push the model to the hub,\n",
    "    # check this guide for more details: https://huggingface.co/transformers/model_sharing.html\n",
    ")"
   ],
   "id": "78797f83fc5bfb71"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# # instantiate trainer\n",
    "# trainer = Seq2SeqTrainer(\n",
    "#     model=model,                     # the instantiated Transformers model to be trained\n",
    "#     tokenizer=image_processor,       # we use the image processor as the tokenizer\n",
    "#     args=training_args,              # pass the training arguments\n",
    "#     compute_metrics=compute_metrics, \n",
    "#     train_dataset=train_dataset,     \n",
    "#     eval_dataset=valid_dataset,      \n",
    "#     data_collator=collate_fn,        \n",
    "# )"
   ],
   "id": "e1b4c138834ec629"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# def get_eval_loader(eval_dataset=None):\n",
    "#   return DataLoader(valid_dataset, collate_fn=collate_fn, batch_size=batch_size)\n",
    "# \n",
    "# def get_test_loader(eval_dataset=None):\n",
    "#   return DataLoader(test_dataset, collate_fn=collate_fn, batch_size=batch_size)\n",
    "# \n",
    "# # override the get_train_dataloader, get_eval_dataloader and\n",
    "# # get_test_dataloader methods of the trainer\n",
    "# # so that we can properly load the data\n",
    "# trainer.get_train_dataloader = lambda: DataLoader(train_dataset, collate_fn=collate_fn, batch_size=batch_size)\n",
    "# trainer.get_eval_dataloader = get_eval_loader\n",
    "# trainer.get_test_dataloader = get_test_loader"
   ],
   "id": "b80862156debf24e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# trainer.train()",
   "id": "550fef0ecfec516c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
