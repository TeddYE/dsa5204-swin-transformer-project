# DSA5204 Swin Transformer Project

## Overview
This project is part of DSA5204, focusing on the Swin Transformer and its applications in computer vision tasks. The primary goal is to compare Swin Transformer with other architectures, such as Vision Transformers (ViT), CNNs, Data-efficient Image Transformers (DeiT), and Pyramid Vision Transformers (PVT), on image classification tasks. The project also extends beyond classification to explore Swin Transformerâ€™s potential in image captioning, demonstrating its adaptability in multimodal learning.
## Objectives

## Methodology
1. **Data Preprocessing**

2. **Model Implementation**

3. **Benchmarking**

4. **Attention Visualization**

5. **Evaluation & Analysis**

## Installation & Requirements

### Dataset Setup

### Training the Model

### Running Benchmark Comparisons

### Attention Visualization

### Image Captioning

## Results & Findings

## Future Work

## References
- Liu, Z., Lin, Y., Cao, Y., et al. **Swin Transformer: Hierarchical Vision Transformer using Shifted Windows**. *ICCV 2021*.
- Dosovitskiy, A., Beyer, L., Kolesnikov, A., et al. **An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale**. *ICLR 2021*.
