{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForImageClassification\n",
    "\n",
    "# download pretrained models\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    'facebook/deit-base-patch16-224',\n",
    "    num_labels=20,  \n",
    "    ignore_mismatched_sizes=True  \n",
    ")\n",
    "\n",
    "# freeze except classifier\n",
    "for name, param in model.named_parameters():\n",
    "    if \"classifier\" not in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# random seed\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#image processing\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from PIL import UnidentifiedImageError\n",
    "from datasets import load_dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "from config import CACHE_DIR\n",
    "\n",
    "IMAGE_SIZE = (224, 224)\n",
    "NUM_CLASSES = 20\n",
    "SEED = 42\n",
    "\n",
    "# Image normalization\n",
    "transform_to_tensor = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# image processing\n",
    "def process_image(image, image_size=IMAGE_SIZE):\n",
    "    try:\n",
    "        if not isinstance(image, Image.Image):\n",
    "            image = Image.fromarray(np.array(image))\n",
    "        image = image.resize(image_size)\n",
    "        tensor = transform_to_tensor(image)\n",
    "        return tensor.numpy()  \n",
    "    except (UnidentifiedImageError, OSError, ValueError) as e:\n",
    "        return None\n",
    "\n",
    "# data loading\n",
    "def load_food(image_size=IMAGE_SIZE, rand_seed=SEED, n_class=NUM_CLASSES):\n",
    "    random.seed(rand_seed)\n",
    "\n",
    "    train_ds = load_dataset(\"ethz/food101\", split=\"train\", cache_dir=CACHE_DIR)\n",
    "    val_ds = load_dataset(\"ethz/food101\", split=\"validation\", cache_dir=CACHE_DIR)\n",
    "\n",
    "    class_names = train_ds.features[\"label\"].names\n",
    "\n",
    "    if os.path.exists(\"selected_classes.json\"):\n",
    "        with open(\"selected_classes.json\", \"r\") as f:\n",
    "            selected_classes = json.load(f)\n",
    "    else:\n",
    "        selected_classes = random.sample(class_names, n_class)\n",
    "        with open(\"selected_classes.json\", \"w\") as f:\n",
    "            json.dump(selected_classes, f)\n",
    "\n",
    "    selected_indices = [class_names.index(c) for c in selected_classes]\n",
    "    label_map = {old: new for new, old in enumerate(selected_indices)}\n",
    "\n",
    "    train_ds = train_ds.filter(lambda x: x[\"label\"] in selected_indices)\n",
    "    val_ds = val_ds.filter(lambda x: x[\"label\"] in selected_indices)\n",
    "\n",
    "    def process_and_relabel(example):\n",
    "        img = process_image(example[\"image\"], image_size)\n",
    "        if img is None:\n",
    "            return {\"image\": None, \"label\": -1}\n",
    "        return {\n",
    "            \"image\": img,\n",
    "            \"label\": label_map[example[\"label\"]]\n",
    "        }\n",
    "\n",
    "    train_ds = train_ds.map(process_and_relabel)\n",
    "    val_ds = val_ds.map(process_and_relabel)\n",
    "    train_ds = train_ds.filter(lambda x: x[\"image\"] is not None and x[\"label\"] != -1)\n",
    "    val_ds = val_ds.filter(lambda x: x[\"image\"] is not None and x[\"label\"] != -1)\n",
    "\n",
    "    return train_ds, val_ds, selected_classes"
   ],
   "id": "8de6cb975ec186b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# create Dataset and DataLoader\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Dataset \n",
    "class Food101Dataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        image = torch.tensor(item[\"image\"], dtype=torch.float32)\n",
    "        label = torch.tensor(item[\"label\"], dtype=torch.long)\n",
    "        return {\n",
    "            \"pixel_values\": image,\n",
    "            \"label\": label\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "# create DataLoader\n",
    "def get_dataloaders(batch_size=BATCH_SIZE):\n",
    "    train_ds, val_ds, class_names = load_food()\n",
    "    train_loader = DataLoader(Food101Dataset(train_ds), batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(Food101Dataset(val_ds), batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader, class_names\n",
    "\n",
    "# get DataLoader for train\n",
    "train_loader, val_loader, selected_classes = get_dataloaders()\n"
   ],
   "id": "8dbd16c4e84cdfa2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch.nn as nn\n",
    "from config import OUTPUT_DIR\n",
    "\n",
    "# train settings\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.classifier.parameters(), lr=5e-4)\n",
    "num_epochs = 5\n",
    "\n",
    "# train the model\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    print(f\" epoch {epoch + 1} begin\")\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        images = batch[\"pixel_values\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(pixel_values=images)\n",
    "        loss = loss_fn(outputs.logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"Epoch {epoch+1}, Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1} finished. Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "model_weight_path = os.path.join(OUTPUT_DIR, \"deit_base_finetuned_food20.pt\")\n",
    "torch.save(model.state_dict(), model_weight_path)"
   ],
   "id": "2c2c62aad06d6ee9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import AutoModelForImageClassification\n",
    "from config import OUTPUT_DIR\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "loaded_model = AutoModelForImageClassification.from_pretrained(\"facebook/deit-base-patch16-224\")\n",
    "loaded_model.classifier = torch.nn.Linear(loaded_model.config.hidden_size, 20)\n",
    "\n",
    "# fine-tuned model\n",
    "state_dict = torch.load(model_weight_path, map_location=device)\n",
    "loaded_model.load_state_dict(state_dict, strict=False)  # 用 strict=False 是因为我们只加载了部分参数\n",
    "\n",
    "loaded_model.to(device)\n",
    "loaded_model.eval()"
   ],
   "id": "be8e5d5280a4d5ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "model = loaded_model  \n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        images = batch[\"pixel_values\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        outputs = model(pixel_values=images)\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# evaluate\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "\n",
    "# print results\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Precision (Macro): {precision:.4f}\")\n",
    "print(f\"Recall (Macro): {recall:.4f}\")\n",
    "print(f\"F1 Score (Macro): {f1:.4f}\")\n",
    "\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "np.fill_diagonal(cm, 0)   \n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=selected_classes,\n",
    "    yticklabels=selected_classes,\n",
    "    vmin=0,\n",
    "    vmax=21\n",
    " )\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"DeiT\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "a21ec2467337c7d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import os\n",
    "\n",
    "from config import IMAGE_DIR, GRAD_CAM_DIR\n",
    "\n",
    "# model\n",
    "model = loaded_model\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "if hasattr(model, \"vit\"):\n",
    "    backbone = model.vit\n",
    "elif hasattr(model, \"deit\"):\n",
    "    backbone = model.deit\n",
    "elif hasattr(model, \"base_model\"):\n",
    "    backbone = model.base_model\n",
    "else:\n",
    "    raise ValueError(\"can't recognize\")\n",
    "\n",
    "# Hook storage\n",
    "activations, gradients = [], []\n",
    "\n",
    "def forward_hook(module, inputs, outputs):\n",
    "    if isinstance(outputs, tuple):\n",
    "        hidden_state = outputs[0]\n",
    "    elif hasattr(outputs, \"last_hidden_state\"):\n",
    "        hidden_state = outputs.last_hidden_state\n",
    "    else:\n",
    "        hidden_state = outputs\n",
    "    activations.append(hidden_state)\n",
    "\n",
    "def backward_hook(module, grad_in, grad_out):\n",
    "    gradients.append(grad_out[0])\n",
    "\n",
    "# Grad-cam\n",
    "def compute_gradcam(input_tensor, model, target_layer):\n",
    "    activations.clear()\n",
    "    gradients.clear()\n",
    "\n",
    "    out = model(input_tensor)\n",
    "    logits = out.logits if hasattr(out, \"logits\") else out[0]\n",
    "    pred = int(logits.argmax(dim=-1).item())\n",
    "\n",
    "    score = logits[0, pred]\n",
    "    model.zero_grad()\n",
    "    score.backward()\n",
    "\n",
    "    A = activations[0]\n",
    "    G = gradients[0]\n",
    "    weights = G.mean(dim=1, keepdim=True)\n",
    "    cam_1d = (weights * A).sum(-1).squeeze(0)\n",
    "    cam_1d = cam_1d[1:]\n",
    "\n",
    "    side = int(cam_1d.size(0)**0.5)\n",
    "    cam_2d = cam_1d.reshape(side, side)\n",
    "    cam_2d = F.interpolate(\n",
    "        cam_2d.unsqueeze(0).unsqueeze(0), size=(224,224),\n",
    "        mode='bilinear', align_corners=False\n",
    "    ).squeeze().detach().cpu().numpy()\n",
    "\n",
    "    cam_2d = (cam_2d - cam_2d.min()) / (cam_2d.max() - cam_2d.min() + 1e-8)\n",
    "    return cam_2d, pred\n",
    "\n",
    "# Image Un-normalization and label mapping\n",
    "def denormalize(tensor_img):\n",
    "    mean = torch.tensor([0.485,0.456,0.406], device=tensor_img.device).view(3,1,1)\n",
    "    std  = torch.tensor([0.229,0.224,0.225], device=tensor_img.device).view(3,1,1)\n",
    "    return torch.clamp(tensor_img * std + mean, 0, 1)\n",
    "\n",
    "def get_label_name(cls_id):\n",
    "    cls_id = int(cls_id)\n",
    "    if hasattr(model, \"config\") and hasattr(model.config, \"id2label\"):\n",
    "        label_map = model.config.id2label\n",
    "        if isinstance(label_map, dict):\n",
    "            return label_map.get(str(cls_id), str(cls_id))\n",
    "        elif isinstance(label_map, list):\n",
    "            return label_map[cls_id] if 0 <= cls_id < len(label_map) else str(cls_id)\n",
    "    return str(cls_id)\n",
    "\n",
    "image_paths = [os.path.join(IMAGE_DIR, fname) for fname in sorted(os.listdir(IMAGE_DIR)) if fname.endswith(\".jpg\") or fname.endswith(\".jpeg\") or fname.endswith(\".png\")]\n",
    "\n",
    "# image processing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "# choose the layer\n",
    "target_layers = [\n",
    "    backbone.encoder.layer[-1].intermediate,\n",
    "    backbone.encoder.layer[-2].intermediate,\n",
    "    backbone.encoder.layer[-3].intermediate\n",
    "]\n",
    "\n",
    "#process and save images\n",
    "def adjust_brightness(img_np, factor=0.7):\n",
    "    img = Image.fromarray((img_np * 255).astype(np.uint8))\n",
    "    enhancer = ImageEnhance.Brightness(img)\n",
    "    img_dark = enhancer.enhance(factor)\n",
    "    return np.array(img_dark) / 255.0\n",
    "\n",
    "for img_path in image_paths:\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    img_dn = denormalize(input_tensor.squeeze(0))\n",
    "    img_np = img_dn.permute(1,2,0).cpu().numpy()\n",
    "    img_np_dark = adjust_brightness(img_np, factor=0.7)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
    "    axs[0].imshow(img_np_dark)\n",
    "    axs[0].set_title(\"Original (Darkened)\")\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    for i, layer in enumerate(target_layers):\n",
    "        fwd_handle = layer.register_forward_hook(forward_hook)\n",
    "        bwd_handle = layer.register_backward_hook(backward_hook)\n",
    "\n",
    "        cam, pred_class = compute_gradcam(input_tensor, model, layer)\n",
    "\n",
    "        axs[i+1].imshow(img_np_dark)\n",
    "        axs[i+1].imshow(cam, cmap='jet', alpha=0.35)  # 更低透明度，突出红色区域\n",
    "        axs[i+1].set_title(f\"Layer -{i+1}\\nPred: {get_label_name(pred_class)}\")\n",
    "        axs[i+1].axis('off')\n",
    "\n",
    "        fwd_handle.remove()\n",
    "        bwd_handle.remove()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    save_path = os.path.join(GRAD_CAM_DIR, f\"{base_name}_styled_gradcam.png\")\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight', pad_inches=0.05)\n",
    "    plt.close(fig)"
   ],
   "id": "597ad4e37d4eb0d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#adjust colors\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from PIL import ImageEnhance\n",
    "\n",
    "def adjust_brightness(img_np, factor=0.85):\n",
    "    img = Image.fromarray((img_np * 255).astype(np.uint8))\n",
    "    enhancer = ImageEnhance.Brightness(img)\n",
    "    img_dark = enhancer.enhance(factor)\n",
    "    return np.array(img_dark) / 255.0\n",
    "\n",
    "for img_path in image_paths:\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    img_dn = denormalize(input_tensor.squeeze(0))\n",
    "    img_np = img_dn.permute(1, 2, 0).cpu().numpy()\n",
    "    img_np_bright = adjust_brightness(img_np, factor=0.85)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
    "    axs[0].imshow(img_np_bright)\n",
    "    axs[0].set_title(\"Original (Lightened)\")\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    for i, layer in enumerate(target_layers):\n",
    "        fwd_handle = layer.register_forward_hook(forward_hook)\n",
    "        bwd_handle = layer.register_backward_hook(backward_hook)\n",
    "\n",
    "        cam, pred_class = compute_gradcam(input_tensor, model, layer)\n",
    "\n",
    "        cam = cam ** 1.5\n",
    "        cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)\n",
    "\n",
    "        cam_rgb = show_cam_on_image(img_np_bright, cam, use_rgb=True)\n",
    "\n",
    "        axs[i+1].imshow(cam_rgb)\n",
    "        axs[i+1].set_title(f\"Layer -{i+1}\\nPred: {get_label_name(pred_class)}\")\n",
    "        axs[i+1].axis('off')\n",
    "\n",
    "        fwd_handle.remove()\n",
    "        bwd_handle.remove()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    save_path = os.path.join(GRAD_CAM_DIR, f\"{base_name}_styled_gradcam_v2.png\")\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight', pad_inches=0.05)\n",
    "    plt.close(fig)"
   ],
   "id": "a63899b52c9320ab"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
